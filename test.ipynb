{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스트리밍 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import os\n",
    "import threading\n",
    "import shutil\n",
    "\n",
    "class Audio_streaming:\n",
    "    def __init__(self, sr=32000, save_sec=10):\n",
    "        '''\n",
    "        마이크를 실시간으로 입력받아 wav파이롤 저장해주는 기능\n",
    "\n",
    "        sr : 샘플레이트\n",
    "        save_sec : 순차적으로 저장될 wav파일의 길이(초)\n",
    "        overlap_sec : 오버랩될 길이(초)\n",
    "        save_path : 저장 경로\n",
    "        '''\n",
    "        self.save_sec = save_sec\n",
    "        self.chunk = sr # chunk 1개는 sr레이트랑 동일하다. 1초라는 의미\n",
    "        self.buffer = [] # chunk를 쌓아두는 리스트\n",
    "        self.lost_secs = 0 # buffer에서 실시간으로 버리는 chunk 개수 기록\n",
    "        self.streaming = True # False가 되면 multi-thread들이 종료된다\n",
    "\n",
    "        # 오디오 관련 선언\n",
    "        self.sr = sr\n",
    "        self.audio = pyaudio.PyAudio()\n",
    "        self.format = pyaudio.paInt16\n",
    "        self.channels = 1\n",
    "        self.stream = self.audio.open(format=self.format, channels=self.channels, rate=self.sr, input=True, frames_per_buffer=self.chunk)\n",
    "\n",
    "    def run(self):\n",
    "        print('오디오 스트리밍, tmp.wav 저장 시작')\n",
    "        threading.Thread(target=self._run).start()\n",
    "\n",
    "    def stop(self):\n",
    "        '''\n",
    "        스트리밍 중지\n",
    "        '''\n",
    "        self.streaming = False\n",
    "\n",
    "\n",
    "    def save_buffer(self):\n",
    "        '''\n",
    "        buffer에 있는 최근의 n초를 저장한다. 계산을 쉽게 하기 위하여 1개의 chunk는 무조건 1초로 한다. 그래서 n초는 buffer에서 n개의 원소를 뜻한다.\n",
    "        '''\n",
    "        # buffer가 n초 이상을 넘어가지 않게 관리한다.\n",
    "        if len(self.buffer) > self.save_sec:\n",
    "            self.lost_secs += len(self.buffer) - self.save_sec\n",
    "            self.buffer = self.buffer[-self.save_sec:]\n",
    "        # 최근의 n초를 저장한다\n",
    "        self._frames_to_wav(self.buffer)\n",
    "\n",
    "        # 버린 누적 chunk와 방금 저장한 buffer의 길이를 반환\n",
    "        return self.lost_secs, len(self.buffer)\n",
    "\n",
    "\n",
    "    def _run(self):\n",
    "        '''\n",
    "        스트리밍하여 buffer에 지속적으로 음성 chunk를 추가만 하는 쓰레드\n",
    "        '''\n",
    "        while self.streaming:\n",
    "            one_chunk = self.stream.read(self.chunk)\n",
    "            self.buffer.append(one_chunk)\n",
    "        print('\\n스트리밍 종료')\n",
    "\n",
    "    def _frames_to_wav(self, frames):\n",
    "        '''\n",
    "        입력된 buffer안의 원소들을 join하여 wav로 저장\n",
    "        '''\n",
    "        # 기존 파일 삭제\n",
    "        wav_name = 'tmp.wav'\n",
    "        if os.path.exists(wav_name):\n",
    "            os.remove(wav_name)\n",
    "        # 새로운 wav 저장\n",
    "        with wave.open(wav_name, 'wb') as wf:\n",
    "            wf.setnchannels(self.channels)\n",
    "            wf.setsampwidth(self.audio.get_sample_size(self.format))\n",
    "            wf.setframerate(self.sr)\n",
    "            wf.writeframes(b''.join(frames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer에 음성 chunk append 시작\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스트리밍 종료\n"
     ]
    }
   ],
   "source": [
    "# 테스트 - class 선언\n",
    "audio_streaming = Audio_streaming()\n",
    "audio_streaming.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 - 버퍼 저장\n",
    "audio_streaming.save_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 - 스트리밍 중지\n",
    "audio_streaming.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STT 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from faster_whisper import WhisperModel\n",
    "import time\n",
    "\n",
    "class STT_faster_whisper:\n",
    "    def __init__(self, model_size='base'):\n",
    "        '''\n",
    "        최대 4배 빠른 faster whisper를 사용하여 cpu로 저장된 wav파일에 STT 수행\n",
    "        \n",
    "        model_size : tiny, tiny.en, base, base.en, small, small.en, medium, medium.en, large-v1, large-v2, large-v3, or large\n",
    "        read_path : wav가 저장되어있는 폴더 경로\n",
    "        '''\n",
    "        # 환경 설정(Window 아나콘다 환경에서 아래 코드 실행 안하면 에러남)\n",
    "        try: os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"true\"\n",
    "        except Exception as e: print(f'os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"true\" 실행해서 발생한 에러. 하지만 무시하고 진행: {e}')\n",
    "\n",
    "        try: os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "        except Exception as e: print(f'os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\" 실행해서 발생한 에러. 하지만 무시하고 진행: {e}')\n",
    "\n",
    "        # 모델 선언\n",
    "        self.model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "    \n",
    "    def run(self, wav_path, last_del=False):\n",
    "        '''\n",
    "        wav 경로를 입력하면 txt로 변경해주고, 각 단어에 대한 time stamp를 반환함\n",
    "\n",
    "        wav_path : STT를 수행할 wav파일 full 경로\n",
    "        last_del : STT된 마지막 word를 지울지. 마지막 word는 끊겼을 수 있다고 가정하기 때문\n",
    "        '''\n",
    "        start = time.time()\n",
    "        # 인퍼런스\n",
    "        segments, info = self.model.transcribe(wav_path, beam_size=5, word_timestamps=True, language='ko')\n",
    "\n",
    "        # 결과 후처리\n",
    "        dic_list = []\n",
    "        for segment in segments:\n",
    "            if segment.no_speech_prob > 0.6: continue # 말을 안했을 확률이 크다고 감지되면 무시\n",
    "            for word in segment.words:\n",
    "                _word = word.word\n",
    "                _start = round(word.start, 2)\n",
    "                _end = round(word.end, 2)\n",
    "                dic_list.append([_word, _start, _end])\n",
    "        self.time = round(time.time()-start, 2)\n",
    "        # 마지막 word 삭제 옵션 적용\n",
    "        if last_del == True and len(dic_list) > 0:\n",
    "            del dic_list[-1]\n",
    "        return dic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' 지금', 2.4, 3.6], [' 녹화를', 3.6, 4.22], [' 하고', 4.22, 4.64], [' 있습니다', 4.64, 5.14], [' 녹음', 5.14, 6.16], [' 테스트', 6.16, 6.5], [' 중입니다', 6.5, 7.1]]\n",
      "0.55\n",
      "[[' 성이', 0.0, 0.3], [' 포함된', 0.3, 0.78], [' 경위라는', 0.78, 1.36], [' 의워도', 1.36, 1.84], [' 길이에', 1.84, 2.32], [' 따른', 2.32, 2.76], [' 음성', 2.76, 3.42], [' 청악해를', 3.42, 4.16], [' 직접', 4.16, 4.5], [' 확인할', 4.5, 5.0], [' 수', 5.0, 5.06], [' 또에', 5.06, 5.3], [' 잘', 5.3, 5.48], [' 수', 5.48, 5.6], [' 있습니다.', 5.6, 5.96]]\n",
      "1.19\n"
     ]
    }
   ],
   "source": [
    "stt_model = STT_faster_whisper()\n",
    "print(stt_model.run(\"test_audio/0.wav\"))\n",
    "print(stt_model.time)\n",
    "\n",
    "print(stt_model.run(\"tmp.wav\"))\n",
    "print(stt_model.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "통합 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Realtime_stt:\n",
    "    def __init__(self, model_size='tiny'):\n",
    "        '''\n",
    "        실시간으로 마이크에서 음성을 저장하는 동시에, 꺼내와서 STT해주는 모듈\n",
    "        핵심 기술:\n",
    "        - 실시간으로 overlap 하여 저장\n",
    "        - 선입선출로 음성을 가져와 STT 추론\n",
    "        - 추론된 결과를 바탕으로 time stamp 기준으로 통합\n",
    "        - 추론된 결과 실시간 제공\n",
    "        '''\n",
    "        self.model_size = model_size\n",
    "        self.streaming = True\n",
    "\n",
    "        self.total_dic_list = [] # 모든 텍스트 히스토리를 저장함\n",
    "        self.stt_model = STT_faster_whisper(model_size)\n",
    "        self.audio_streaming = Audio_streaming()\n",
    "        self.txt_log = ''\n",
    "        \n",
    "    def run(self):\n",
    "        self.audio_streaming.run()\n",
    "        threading.Thread(target=self._run).start()\n",
    "        \n",
    "    def _run(self):\n",
    "        while self.streaming:\n",
    "            # 최근 오디오(최대10초) 저장\n",
    "            lost_secs, buffer_len = self.audio_streaming.save_buffer()\n",
    "            time.sleep(0.05)\n",
    "            # 저장된 오디오 STT(마지막 word 제외)\n",
    "            new_dic_list = self.stt_model.run('tmp.wav', last_del=True)\n",
    "            updated_dic_list = self._time_update(new_dic_list, lost_secs)\n",
    "            # total_dic_list에 새로운 텍스트 중복 제거 병합\n",
    "            self.total_dic_list = self._murge_dic_list(self.total_dic_list, updated_dic_list)\n",
    "            # 결과 출력\n",
    "            result_txt = self._get_txt_from_dic_list(self.total_dic_list)\n",
    "            self._txt_out(result_txt)\n",
    "\n",
    "        \n",
    "    def _time_update(self, new_dic_list, lost_secs):\n",
    "        '''\n",
    "        new_dic_list의 start, end 값들을 실제 처럼 업데이트\n",
    "        '''\n",
    "        updated_dic_list = []\n",
    "        for dic in new_dic_list:\n",
    "            dic[1] += lost_secs\n",
    "            dic[2] += lost_secs\n",
    "            updated_dic_list.append(dic)\n",
    "        return updated_dic_list\n",
    "            \n",
    "    def _murge_dic_list(self, total_dic_list, new_dic_list):\n",
    "        '''\n",
    "        time stamp를 확인하여 두 stt결과를 중복 제거하여 병합\n",
    "        '''\n",
    "        # 마지막 단어가 끝나는 시점 가져오기\n",
    "        if len(total_dic_list) > 0:\n",
    "            last_end = total_dic_list[-1][2]\n",
    "        else:\n",
    "            last_end = 0\n",
    "        # 새로운 리스트 병합하기\n",
    "        for i, dic in enumerate(new_dic_list):\n",
    "            # 첫 번째 인식한 단어는 지우기\n",
    "            if i == 0: continue\n",
    "            # 추가 조건 확인\n",
    "            if dic[1] >= last_end: # dic 데이터 예시: [word, start, end]\n",
    "                total_dic_list.append(dic)\n",
    "            else:\n",
    "                continue\n",
    "        return total_dic_list\n",
    "            \n",
    "    def _get_txt_from_dic_list(self, dic_list):\n",
    "        '''\n",
    "        dic_list에서 txt만 뽑아서 반환\n",
    "        '''\n",
    "        txt = ''\n",
    "        for dic in dic_list:\n",
    "            new_txt = dic[0]\n",
    "            txt = f'{txt}{new_txt}'\n",
    "        return txt\n",
    "    \n",
    "    def _txt_out(self, txt):\n",
    "        '''\n",
    "        전체 텍스트를 출력 요청하면, 지금까지 출력된 텍스트를 제외하고 출력\n",
    "        '''\n",
    "        new_txt = txt[len(self.txt_log):]\n",
    "        if len(new_txt) > 0:\n",
    "            print(new_txt, end='')\n",
    "        self.txt_log = txt\n",
    "\n",
    "    def stop(self):\n",
    "        '''\n",
    "        멀티쓰레드로 구동되는 스트리밍 로직을 중지\n",
    "        '''\n",
    "        print('프로세스 중지 중...')\n",
    "        self.audio_streaming.stop()\n",
    "        self.streaming = False\n",
    "\n",
    "realtime_stt = Realtime_stt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오디오 스트리밍, tmp.wav 저장 시작\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 코드는 2개의 오디오 바일을 비교하여 텍스트로 결과를 비교하면 이 방법을 통해 도전히 포함된 경위라는 무회도 길이 됐다는 음성 정학의 를 직접 확인할 수도"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-38 (_run):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\112fk\\anaconda3\\envs\\whisper\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\112fk\\anaconda3\\envs\\whisper\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\112fk\\anaconda3\\envs\\whisper\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\112fk\\AppData\\Local\\Temp\\ipykernel_2492\\3187673815.py\", line 28, in _run\n",
      "  File \"C:\\Users\\112fk\\AppData\\Local\\Temp\\ipykernel_2492\\1406802704.py\", line 50, in save_buffer\n",
      "  File \"C:\\Users\\112fk\\AppData\\Local\\Temp\\ipykernel_2492\\1406802704.py\", line 72, in _frames_to_wav\n",
      "PermissionError: [WinError 32] 다른 프로세스가 파일을 사용 중이기 때문에 프로세스가 액세스 할 수 없습니다: 'tmp.wav'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 잘 수\n",
      "스트리밍 종료\n"
     ]
    }
   ],
   "source": [
    "realtime_stt.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프로세스 중지 중...\n"
     ]
    }
   ],
   "source": [
    "realtime_stt.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
